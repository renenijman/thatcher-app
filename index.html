<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Thatcher Effect App</title>
    
    <!-- PWA Meta Tags -->
    <link rel="manifest" href="manifest.json">
    <meta name="theme-color" content="#1a2a6c">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="mobile-web-app-capable" content="yes">
    
    <!-- MediaPipe Vision Tasks -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/vision_bundle.min.js" crossorigin="anonymous"></script>
    
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }
        
        body {
            background: linear-gradient(135deg, #1a2a6c, #b21f1f, #1a2a6c);
            color: white;
            min-height: 100vh;
            padding: 20px;
            display: flex;
            flex-direction: column;
            align-items: center;
        }
        
        .container {
            max-width: 800px;
            width: 100%;
            background: rgba(0, 0, 0, 0.7);
            border-radius: 20px;
            padding: 20px;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.5);
            margin-top: 20px;
            backdrop-filter: blur(10px);
        }
        
        header {
            text-align: center;
            margin-bottom: 20px;
        }
        
        h1 {
            font-size: 2.5rem;
            margin-bottom: 10px;
            text-shadow: 0 0 10px rgba(255, 255, 255, 0.5);
        }
        
        .subtitle {
            font-size: 1.1rem;
            opacity: 0.9;
            margin-bottom: 20px;
        }
        
        .input-section {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            justify-content: center;
            margin-bottom: 20px;
        }
        
        .btn {
            background: linear-gradient(to right, #4A00E0, #8E2DE2);
            color: white;
            border: none;
            padding: 12px 25px;
            border-radius: 50px;
            font-size: 1rem;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
            display: flex;
            align-items: center;
            gap: 8px;
        }
        
        .btn:hover {
            transform: translateY(-3px);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
        }
        
        .btn:active {
            transform: translateY(1px);
        }
        
        .btn:disabled {
            background: #555;
            cursor: not-allowed;
            transform: none;
            box-shadow: none;
        }
        
        #fileInput {
            display: none;
        }
        
        .canvas-container {
            position: relative;
            width: 100%;
            max-width: 100%;
            background: #000;
            border-radius: 15px;
            overflow: hidden;
            margin: 0 auto;
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.5);
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 200px;
        }
        
        canvas {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            max-width: 100%;
            max-height: 100%;
        }
        
        #originalCanvas {
            z-index: 1;
        }
        
        #processedCanvas {
            z-index: 2;
        }
        
        .controls {
            display: flex;
            flex-wrap: wrap;
            gap: 15px;
            justify-content: center;
            margin-top: 20px;
        }
        
        .status {
            text-align: center;
            padding: 10px;
            margin: 10px 0;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
            word-break: break-word;
        }
        
        .loading {
            display: none;
            text-align: center;
            padding: 20px;
        }
        
        .spinner {
            border: 4px solid rgba(255, 255, 255, 0.3);
            border-radius: 50%;
            border-top: 4px solid #fff;
            width: 40px;
            height: 40px;
            animation: spin 1s linear infinite;
            margin: 0 auto 15px;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .instructions {
            margin-top: 20px;
            padding: 15px;
            background: rgba(0, 0, 0, 0.4);
            border-radius: 10px;
            font-size: 0.9rem;
        }
        
        .instructions h3 {
            margin-bottom: 10px;
        }
        
        .instructions ol {
            padding-left: 20px;
        }
        
        .instructions li {
            margin-bottom: 8px;
        }

        @media (max-width: 600px) {
            .container {
                padding: 15px;
            }
            
            h1 {
                font-size: 2rem;
            }
            
            .input-section {
                flex-direction: column;
                align-items: center;
            }
            
            .btn {
                width: 100%;
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>Thatcher Effect</h1>
            <p class="subtitle">Automatic face detection - flip eyes and mouth</p>
        </header>
        
        <div class="input-section">
            <button id="uploadBtn" class="btn">
                ðŸ“· Take Photo or Upload
            </button>
            <input type="file" id="fileInput" accept="image/*">
        </div>
        
        <div class="canvas-container" id="canvasContainer">
            <canvas id="originalCanvas"></canvas>
            <canvas id="processedCanvas"></canvas>
        </div>
        
        <div class="status" id="status">Loading face detection model...</div>
        
        <div class="loading" id="loading">
            <div class="spinner"></div>
            <p>Processing image...</p>
        </div>
        
        <div class="controls">
            <button id="processBtn" class="btn" disabled>
                âš¡ Apply Thatcher Effect
            </button>
            <button id="resetBtn" class="btn">
                ðŸ”„ Reset
            </button>
        </div>
        
        <textarea id="debugLog" readonly style="width:100%; height:150px; background:#111; color:#0f0; font-family:monospace; font-size:12px; padding:10px; border-radius:8px; border:1px solid #333; margin:10px 0;"></textarea>
        
        <div class="instructions">
            <h3>How to Use:</h3>
            <ol>
                <li>Tap the button to take a photo or choose from gallery</li>
                <li>Click "Apply Thatcher Effect" to process the image</li>
                <li>See the face with eyes and mouth flipped upside down</li>
            </ol>
        </div>
    </div>

    <script>
        const { FaceLandmarker, FilesetResolver } = vision;
        
        // DOM elements
        const originalCanvas = document.getElementById('originalCanvas');
        const processedCanvas = document.getElementById('processedCanvas');
        const canvasContainer = document.getElementById('canvasContainer');
        const fileInput = document.getElementById('fileInput');
        const uploadBtn = document.getElementById('uploadBtn');
        const processBtn = document.getElementById('processBtn');
        const resetBtn = document.getElementById('resetBtn');
        const statusEl = document.getElementById('status');
        const loadingEl = document.getElementById('loading');
        
        const originalCtx = originalCanvas.getContext('2d');
        const processedCtx = processedCanvas.getContext('2d');
        
        let currentImage = null;
        let faceLandmarker = null;
        let lastLandmarks = null;

        // MediaPipe FaceMesh indices for eyes and lips
        const LEFT_EYE_INDICES = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246];
        const RIGHT_EYE_INDICES = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398];
        const LIPS_INDICES = [61, 146, 91, 181, 84, 17, 314, 405, 321, 375, 291, 409, 270, 269, 267, 0, 37, 39, 40, 185];

        // Debug logging
        const debugLog = document.getElementById('debugLog');
        function log(msg) {
            const time = new Date().toLocaleTimeString();
            debugLog.value += "[" + time + "] " + msg + "\n";
            debugLog.scrollTop = debugLog.scrollHeight;
            console.log(msg);
        }

        async function init() {
            log("=== MediaPipe Init ===");
            
            try {
                log("Step 1: Loading WASM files...");
                const filesetResolver = await FilesetResolver.forVisionTasks(
                    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/wasm"
                );
                log("  WASM loaded OK");
                
                log("Step 2: Loading face model (GPU)...");
                log("  URL: storage.googleapis.com/mediapipe-models/...");
                
                faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                    baseOptions: {
                        modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
                        delegate: "GPU"
                    },
                    runningMode: "IMAGE",
                    numFaces: 1,
                    outputFaceBlendshapes: false,
                    outputFacialTransformationMatrixes: false
                });
                
                log("Step 3: SUCCESS!");
                statusEl.textContent = "Ready! Tap to take photo or upload.";
                processBtn.disabled = false;
                
            } catch (error) {
                log("GPU Error: " + error.message);
                
                // Try CPU fallback
                try {
                    log("Trying CPU mode...");
                    const filesetResolver = await FilesetResolver.forVisionTasks(
                        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.8/wasm"
                    );
                    
                    faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                        baseOptions: {
                            modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task",
                            delegate: "CPU"
                        },
                        runningMode: "IMAGE",
                        numFaces: 1
                    });
                    
                    log("CPU mode SUCCESS!");
                    statusEl.textContent = "Ready (CPU)! Tap to take photo or upload.";
                    processBtn.disabled = false;
                } catch (e2) {
                    log("CPU Error: " + e2.message);
                    log("Stack: " + (e2.stack || 'no stack'));
                    statusEl.textContent = "Failed - see log";
                }
            }
        }

        function updateCanvasContainer(width, height) {
            const containerWidth = canvasContainer.clientWidth;
            const aspectRatio = height / width;
            const newHeight = Math.min(containerWidth * aspectRatio, 600);
            canvasContainer.style.height = newHeight + 'px';
        }

        // File upload
        uploadBtn.addEventListener('click', () => fileInput.click());
        
        fileInput.addEventListener('change', (e) => {
            if (e.target.files && e.target.files[0]) {
                const reader = new FileReader();
                reader.onload = (event) => loadImage(event.target.result);
                reader.readAsDataURL(e.target.files[0]);
            }
        });

        function loadImage(src) {
            const img = new Image();
            img.onload = () => {
                originalCanvas.width = img.width;
                originalCanvas.height = img.height;
                processedCanvas.width = img.width;
                processedCanvas.height = img.height;
                
                updateCanvasContainer(img.width, img.height);
                
                originalCtx.drawImage(img, 0, 0);
                processedCtx.clearRect(0, 0, processedCanvas.width, processedCanvas.height);
                
                currentImage = img;
                lastLandmarks = null;
                statusEl.textContent = "Image loaded. Click 'Apply Thatcher Effect' to process.";
            };
            img.src = src;
        }

        // Process image
        processBtn.addEventListener('click', async () => {
            if (!currentImage || !faceLandmarker) {
                statusEl.textContent = "Please upload an image first.";
                return;
            }
            
            try {
                loadingEl.style.display = 'block';
                statusEl.textContent = "Detecting face...";
                
                const result = faceLandmarker.detect(currentImage);
                
                if (!result.faceLandmarks || result.faceLandmarks.length === 0) {
                    statusEl.textContent = "No face detected. Try another image.";
                    loadingEl.style.display = 'none';
                    return;
                }
                
                lastLandmarks = result.faceLandmarks[0];
                statusEl.textContent = "Face detected! Applying effect...";
                
                applyThatcherEffect();
                
                statusEl.textContent = "Thatcher effect applied!";
                loadingEl.style.display = 'none';
                
            } catch (error) {
                console.error("Process error:", error);
                statusEl.textContent = "Error: " + error.message;
                loadingEl.style.display = 'none';
            }
        });

        function getBoundingBox(indices, padding = 1.3) {
            let minX = Infinity, maxX = -Infinity;
            let minY = Infinity, maxY = -Infinity;
            
            const w = originalCanvas.width;
            const h = originalCanvas.height;
            
            for (const idx of indices) {
                const point = lastLandmarks[idx];
                if (point) {
                    const x = point.x * w;
                    const y = point.y * h;
                    minX = Math.min(minX, x);
                    maxX = Math.max(maxX, x);
                    minY = Math.min(minY, y);
                    maxY = Math.max(maxY, y);
                }
            }
            
            const width = maxX - minX;
            const height = maxY - minY;
            const centerX = (minX + maxX) / 2;
            const centerY = (minY + maxY) / 2;
            
            const paddedWidth = width * padding;
            const paddedHeight = height * padding;
            
            return {
                x: Math.floor(centerX - paddedWidth / 2),
                y: Math.floor(centerY - paddedHeight / 2),
                width: Math.ceil(paddedWidth),
                height: Math.ceil(paddedHeight)
            };
        }

        function applyThatcherEffect() {
            processedCtx.clearRect(0, 0, processedCanvas.width, processedCanvas.height);
            processedCtx.drawImage(originalCanvas, 0, 0);
            
            if (!lastLandmarks) return;
            
            const leftEyeBox = getBoundingBox(LEFT_EYE_INDICES, 1.5);
            const rightEyeBox = getBoundingBox(RIGHT_EYE_INDICES, 1.5);
            const mouthBox = getBoundingBox(LIPS_INDICES, 1.4);
            
            flipRegion(leftEyeBox);
            flipRegion(rightEyeBox);
            flipRegion(mouthBox);
        }

        function flipRegion(box) {
            const x = Math.max(0, box.x);
            const y = Math.max(0, box.y);
            const width = Math.min(box.width, processedCanvas.width - x);
            const height = Math.min(box.height, processedCanvas.height - y);
            
            if (width <= 0 || height <= 0) return;
            
            // Extract region
            const tempCanvas = document.createElement('canvas');
            tempCanvas.width = width;
            tempCanvas.height = height;
            const tempCtx = tempCanvas.getContext('2d');
            tempCtx.drawImage(originalCanvas, x, y, width, height, 0, 0, width, height);
            
            // Flip vertically
            const flippedCanvas = document.createElement('canvas');
            flippedCanvas.width = width;
            flippedCanvas.height = height;
            const flippedCtx = flippedCanvas.getContext('2d');
            flippedCtx.translate(0, height);
            flippedCtx.scale(1, -1);
            flippedCtx.drawImage(tempCanvas, 0, 0);
            
            // Create mask
            const maskCanvas = document.createElement('canvas');
            maskCanvas.width = width;
            maskCanvas.height = height;
            const maskCtx = maskCanvas.getContext('2d');
            
            const cx = width / 2;
            const cy = height / 2;
            const rx = width / 2;
            const ry = height / 2;
            
            const gradient = maskCtx.createRadialGradient(cx, cy, 0, cx, cy, Math.max(rx, ry));
            gradient.addColorStop(0, 'rgba(255,255,255,1)');
            gradient.addColorStop(0.6, 'rgba(255,255,255,1)');
            gradient.addColorStop(0.85, 'rgba(255,255,255,0.5)');
            gradient.addColorStop(1, 'rgba(255,255,255,0)');
            
            maskCtx.fillStyle = gradient;
            maskCtx.beginPath();
            maskCtx.ellipse(cx, cy, rx, ry, 0, 0, Math.PI * 2);
            maskCtx.fill();
            
            // Apply mask
            const resultCanvas = document.createElement('canvas');
            resultCanvas.width = width;
            resultCanvas.height = height;
            const resultCtx = resultCanvas.getContext('2d');
            resultCtx.drawImage(flippedCanvas, 0, 0);
            resultCtx.globalCompositeOperation = 'destination-in';
            resultCtx.drawImage(maskCanvas, 0, 0);
            
            // Composite
            processedCtx.globalCompositeOperation = 'destination-out';
            processedCtx.drawImage(maskCanvas, x, y);
            processedCtx.globalCompositeOperation = 'source-over';
            processedCtx.drawImage(resultCanvas, x, y);
        }

        // Reset
        resetBtn.addEventListener('click', () => {
            originalCtx.clearRect(0, 0, originalCanvas.width, originalCanvas.height);
            processedCtx.clearRect(0, 0, processedCanvas.width, processedCanvas.height);
            currentImage = null;
            lastLandmarks = null;
            statusEl.textContent = "Reset. Upload an image to begin.";
        });

        // Register Service Worker
        if ('serviceWorker' in navigator) {
            navigator.serviceWorker.register('./sw.js').catch(e => console.log('SW error:', e));
        }

        // Initialize
        init();
    </script>
</body>
</html>

